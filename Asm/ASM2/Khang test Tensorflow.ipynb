{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.style.use('dark_background')\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Using Tensorflow version:', tf.__version__)\n",
    "\n",
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv('data_labels_mainData.csv')\n",
    "extra_data = pd.read_csv('data_labels_extraData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting cellType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train, test, validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = main_data['ImageName']\n",
    "Y = main_data['cellType']\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.33, random_state=99)\n",
    "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=0.2, random_state=99)\n",
    "\n",
    "trainY = trainY.ravel()\n",
    "testY = testY.ravel()\n",
    "valY = valY.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(valX.shape)\n",
    "print(valY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_img_list = trainX.tolist()\n",
    "testX_img_list = testX.tolist()\n",
    "valX_img_list = valX.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_dataset(directory, img_list):\n",
    "    IMAGE_SIZE = 27\n",
    "    train_data = []\n",
    "    for img in tqdm(img_list, desc='Extracting Image Progress'):\n",
    "        path = os.path.join(directory, img)\n",
    "        img = cv2.resize(cv2.imread(path), (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        train_data.append(np.array(img))\n",
    "    print(\"Successfully import images!\")\n",
    "    # Convert to np.array and normalize pixel values to be between 0 and 1 \n",
    "    return np.array(train_data).astype('float32') / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THE PATH TO IMAGE FOLDER IN YOUR LOCAL DEVICE!\n",
    "# Khang desktop: C:\\Users\\User\\Desktop\\RMIT\\Cloud - GitHub\\Minh\\ML\\Asm\\ASM2\\patch_images\n",
    "# Khang laptop: C:\\Users\\Laptop\\Desktop\\RMIT\\Cloud-GitHub\\Minh\\ML\\Asm\\ASM2\\patch_images\n",
    "path = r\"C:\\Users\\User\\Desktop\\RMIT\\Cloud - GitHub\\Minh\\ML\\Asm\\ASM2\\patch_images\"\n",
    "\n",
    "trainX_img = create_img_dataset(path, trainX_img_list)\n",
    "testX_img = create_img_dataset(path, testX_img_list)\n",
    "valX_img = create_img_dataset(path, valX_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainX_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(testX_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(valX_img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=trainX_img.shape[1:], activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,padding='same', activation='relu', input_shape=trainX_img.shape[1:]))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(lr=0.000001)\n",
    "model.compile(optimizer = opt,\n",
    "              loss = 'sparse_categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                                   featurewise_std_normalization=True, \n",
    "                                   rotation_range=20, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest', \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2)\n",
    "\n",
    "train_it = train_datagen.flow(trainX_img, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "early = EarlyStopping(monitor='accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "hist = model.fit(trainX_img, trainY, \n",
    "                 validation_data = (valX_img, valY),\n",
    "                 batch_size = 32, \n",
    "                 epochs = 200, \n",
    "                 verbose=1,\n",
    "                 callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# Summarize history for loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(testX_img)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "\n",
    "print(classification_report(testY, predictions, target_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
